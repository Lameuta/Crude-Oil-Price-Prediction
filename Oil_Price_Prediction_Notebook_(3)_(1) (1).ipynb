{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "052196fb",
      "metadata": {
        "id": "052196fb"
      },
      "source": [
        "# Oil Price Prediction\n",
        "\n",
        "This notebook loads a cleaned dataset and applies:\n",
        "- Classic Machine Learning models (Linear Regression, Random Forest, etc.)\n",
        "- Time Series forecasting using Prophet\n",
        "- Rerun EVERY cells when you change the resample_frequency to get different time granularity\n",
        "\n",
        "to predict the future WTI Crude oil prices."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "h8jwiESiIwjD",
      "metadata": {
        "id": "h8jwiESiIwjD"
      },
      "outputs": [],
      "source": [
        "# Cell 1: Import Libraries and Utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "\n",
        "# Import the utility classes\n",
        "from oil_prediction_utils import *\n",
        "warnings.filterwarnings('ignore')\n",
        "print(\"All libraries and utilities imported successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "OR1BubGoIzLc",
      "metadata": {
        "id": "OR1BubGoIzLc"
      },
      "outputs": [],
      "source": [
        "file_path = '/content/relevant_features_1.csv'\n",
        "df = pd.read_csv(file_path)\n",
        "print(\"Dataset loaded successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-cA0N6dNMP0k",
      "metadata": {
        "id": "-cA0N6dNMP0k"
      },
      "outputs": [],
      "source": [
        "resample_frequency = 'W'  # Change to 'D', 'W', or 'M'\n",
        "\n",
        "# Get configuration using the utility\n",
        "config = DataProcessor.get_frequency_config(resample_frequency)\n",
        "freq_str = config['freq_str']\n",
        "lags = config['lags']\n",
        "window_sizes = config['window_sizes']\n",
        "initial_train_periods = config['initial_train_periods']\n",
        "test_periods = config['test_periods']\n",
        "forecast_periods = config['forecast_periods']\n",
        "seasonal_period = config['seasonal_period']\n",
        "\n",
        "print(f\"Configuration set for {freq_str}ly frequency.\")\n",
        "print(f\"   - Lags: {lags}\")\n",
        "print(f\"   - Windows: {window_sizes}\")\n",
        "print(f\"   - Test Periods: {test_periods}\")\n",
        "print(f\"   - Forecast Periods: {forecast_periods}\")\n",
        "print(f\"   - SARIMA Seasonal Period: {seasonal_period}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "DGS1ZLmdIz4L",
      "metadata": {
        "id": "DGS1ZLmdIz4L"
      },
      "outputs": [],
      "source": [
        "# Cell 3: Data Preprocessing\n",
        "df_processed = DataProcessor.preprocess_data(df, resample_frequency)\n",
        "print(f\"Data preprocessed and resampled to {freq_str}ly frequency.\")\n",
        "df_processed.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "qyiy3JtJI442",
      "metadata": {
        "id": "qyiy3JtJI442"
      },
      "outputs": [],
      "source": [
        "# Cell 4: Initialize Components\n",
        "target_col = 'WTI_Crude'\n",
        "date_col = 'Date'\n",
        "\n",
        "# Initialize the backtester\n",
        "backtester = ModelBacktester(df_processed, target_col, date_col)\n",
        "print(\"Backtester initialized successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9PSVI-ZaI-V3",
      "metadata": {
        "id": "9PSVI-ZaI-V3"
      },
      "outputs": [],
      "source": [
        "# Cell 5 & 6: Run Backtesting\n",
        "print(f\"Starting backtesting with {test_periods} test periods...\")\n",
        "\n",
        "backtest_results = backtester.walk_forward_validation_realistic(\n",
        "    initial_train_periods=initial_train_periods,\n",
        "    total_test_periods=test_periods,\n",
        "    p_lags=lags,\n",
        "    p_window_sizes=window_sizes,\n",
        "    seasonal_period=seasonal_period\n",
        ")\n",
        "\n",
        "print(f\"Calculating performance metrics for all models ({freq_str}ly)...\")\n",
        "performance_metrics = backtester.calculate_metrics()\n",
        "\n",
        "print(f\"REALISTIC BACKTESTING PERFORMANCE METRICS ({freq_str.upper()}LY)\")\n",
        "print(\"=\"*70)\n",
        "print(performance_metrics.round(4))\n",
        "print(\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "_yeJvqgjJDVx",
      "metadata": {
        "id": "_yeJvqgjJDVx"
      },
      "outputs": [],
      "source": [
        "# Cell 7: Future Forecasting Setup\n",
        "forecaster = ModelForecaster(target_col, date_col)\n",
        "\n",
        "# Prepare full dataset for final training\n",
        "print(\"Preparing full dataset features for final model training...\")\n",
        "full_featured_data = backtester.prepare_features_historical_only(\n",
        "    df_processed, lags, window_sizes\n",
        ").dropna()\n",
        "\n",
        "feature_cols = backtester.get_feature_columns(full_featured_data)\n",
        "X_full = full_featured_data[feature_cols]\n",
        "y_full = full_featured_data[target_col]\n",
        "\n",
        "print(f\"Training data prepared up to: {full_featured_data[date_col].max().strftime('%Y-%m-%d')}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "-rFnF8HMJOMq",
      "metadata": {
        "id": "-rFnF8HMJOMq"
      },
      "outputs": [],
      "source": [
        "# Cell 8: Generate Future Forecasts for All Models\n",
        "future_forecasts_all_models = {}\n",
        "\n",
        "# Models to forecast (excluding ARIMA and SARIMA)\n",
        "models_to_forecast = ['Linear Regression', 'Ridge Regression', 'Random Forest',\n",
        "                     'Gradient Boosting', 'Prophet']\n",
        "\n",
        "for model_name in models_to_forecast:\n",
        "    print(f\"Generating future forecast for: {model_name}\")\n",
        "\n",
        "    try:\n",
        "        if model_name == 'Prophet':\n",
        "            # Prophet forecasting\n",
        "            future_predictions_df = forecaster.forecast_prophet_model(\n",
        "                full_featured_data, feature_cols, forecast_periods, resample_frequency\n",
        "            )\n",
        "\n",
        "        else:\n",
        "            # Sklearn models forecasting\n",
        "            sklearn_models = forecaster.get_sklearn_models()\n",
        "            final_model = sklearn_models[model_name]\n",
        "            final_model.fit(X_full, y_full)\n",
        "\n",
        "            # Get recent data for iterative forecasting\n",
        "            max_feature_period = max(max(lags), max(window_sizes))\n",
        "            last_known_data = df_processed.iloc[-max_feature_period:].copy()\n",
        "\n",
        "            future_predictions_df = forecaster.forecast_sklearn_model(\n",
        "                final_model, full_featured_data, last_known_data,\n",
        "                forecast_periods, resample_frequency, lags, window_sizes\n",
        "            )\n",
        "\n",
        "        future_forecasts_all_models[model_name] = future_predictions_df\n",
        "        print(f\"Forecast generated successfully for {model_name}\")\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error generating forecast for {model_name}: {e}\")\n",
        "        future_forecasts_all_models[model_name] = pd.DataFrame({date_col: [], 'Forecast': []})\n",
        "\n",
        "print(\"Future forecasts generated for all selected models.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "97f2289b",
      "metadata": {
        "id": "97f2289b"
      },
      "outputs": [],
      "source": [
        "# Cell 9: Structure Data for Power BI Export\n",
        "print(\"Structuring data for Power BI export...\")\n",
        "\n",
        "combined_data_export = DataExporter.structure_data_for_powerbi(\n",
        "    df_processed, backtest_results, future_forecasts_all_models,\n",
        "    target_col, date_col, exclude_models=['ARIMA', 'SARIMA']\n",
        ")\n",
        "\n",
        "print(\"Data structured successfully!\")\n",
        "print(\"Sample of combined data:\")\n",
        "print(combined_data_export.head())\n",
        "print(combined_data_export.tail())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7e8211e",
      "metadata": {
        "id": "e7e8211e"
      },
      "source": [
        "## Structure data for power bi (revised)\n",
        "\n",
        "### Subtask:\n",
        "Combine historical actuals, backtest predictions for all models, and future forecasts for all models into a single DataFrame with 'Date', 'DataType', 'Model', and 'Value' columns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bd82a19e",
      "metadata": {
        "id": "bd82a19e"
      },
      "outputs": [],
      "source": [
        "# Cell 10: Export to CSV\n",
        "combined_data_filename = f'combined_oil_price_data_{resample_frequency}.csv'\n",
        "DataExporter.export_to_csv(combined_data_export, combined_data_filename)\n",
        "\n",
        "# Also export performance metrics\n",
        "metrics_filename = f'performance_metrics_{resample_frequency}.csv'\n",
        "performance_metrics.to_csv(metrics_filename, index=True)\n",
        "print(f\"Performance metrics exported to '{metrics_filename}'\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0caf0d88",
      "metadata": {
        "id": "0caf0d88"
      },
      "outputs": [],
      "source": [
        "# Cell 11: Visualization\n",
        "print(\"Creating comprehensive visualization...\")\n",
        "\n",
        "# Determine forecast start date\n",
        "forecast_start_date = df_processed[date_col].max()\n",
        "\n",
        "# Create the plot\n",
        "Visualizer.plot_results(\n",
        "    combined_data_export,\n",
        "    target_col='Value',  # Note: Value column in combined data\n",
        "    date_col=date_col,\n",
        "    forecast_start_date=forecast_start_date,\n",
        "    title=f'{target_col} Price: Historical, Backtest & Forecast ({freq_str}ly Data)'\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5da37c46",
      "metadata": {
        "id": "5da37c46"
      },
      "source": [
        "## Export to csv (revised)\n",
        "\n",
        "### Subtask:\n",
        "Save the combined DataFrame to a CSV file.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ee413b3",
      "metadata": {
        "id": "5ee413b3"
      },
      "outputs": [],
      "source": [
        "# Cell 12: Best Model Analysis and Individual Forecast\n",
        "if not performance_metrics.empty and 'R²' in performance_metrics.columns:\n",
        "    # Find best model based on R²\n",
        "    best_model_name = performance_metrics.dropna()['R²'].idxmax()\n",
        "    print(f\"Best model based on R²: {best_model_name}\")\n",
        "    print(f\"Performance: {performance_metrics.loc[best_model_name].round(4)}\")\n",
        "\n",
        "    # Plot individual best model forecast\n",
        "    if best_model_name in future_forecasts_all_models:\n",
        "        best_forecast = future_forecasts_all_models[best_model_name]\n",
        "\n",
        "        plt.figure(figsize=(16, 8))\n",
        "\n",
        "        # Plot recent historical data\n",
        "        recent_periods = forecast_periods * 3\n",
        "        recent_data = df_processed.iloc[-recent_periods:]\n",
        "        plt.plot(recent_data[date_col], recent_data[target_col],\n",
        "                label=f'Historical {target_col}', color='royalblue', linewidth=2)\n",
        "\n",
        "        # Plot best model forecast\n",
        "        if not best_forecast.empty:\n",
        "            plt.plot(best_forecast[date_col], best_forecast['Forecast'],\n",
        "                    label=f'{best_model_name} Forecast', color='darkorange',\n",
        "                    linestyle='--', marker='o', markersize=4)\n",
        "\n",
        "        plt.axvline(forecast_start_date, color='red', linestyle=':',\n",
        "                   linewidth=2, label='Forecast Start')\n",
        "\n",
        "        plt.title(f'{target_col}: Best Model ({best_model_name}) Forecast',\n",
        "                 fontsize=16, fontweight='bold')\n",
        "        plt.xlabel('Date', fontsize=12)\n",
        "        plt.ylabel(f'Price (USD)', fontsize=12)\n",
        "        plt.legend(fontsize=12)\n",
        "        plt.grid(True, alpha=0.3)\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d07cb6c",
      "metadata": {
        "id": "0d07cb6c"
      },
      "outputs": [],
      "source": [
        "# Cell 13: Summary Statistics\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"ANALYSIS SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "print(f\"Data Frequency: {freq_str}ly\")\n",
        "print(f\"Historical Data Points: {len(df_processed)}\")\n",
        "print(f\"Backtest Periods: {len(backtest_results) if 'backtest_results' in locals() else 'N/A'}\")\n",
        "print(f\"Forecast Periods: {forecast_periods}\")\n",
        "\n",
        "print(f\"\\nModels Evaluated: {len(performance_metrics)}\")\n",
        "for model in performance_metrics.index:\n",
        "    r2 = performance_metrics.loc[model, 'R²']\n",
        "    mae = performance_metrics.loc[model, 'MAE']\n",
        "    dir_acc = performance_metrics.loc[model, 'Directional_Accuracy']\n",
        "    print(f\"  {model}: R²={r2:.3f}, MAE=${mae:.2f}, Dir.Acc={dir_acc:.1f}%\")\n",
        "\n",
        "print(f\"\\nData Export:\")\n",
        "print(f\"  Combined Data: {combined_data_filename}\")\n",
        "print(f\"  Performance Metrics: {metrics_filename}\")\n",
        "print(f\"  Total Records in Combined Data: {len(combined_data_export)}\")\n",
        "\n",
        "data_type_counts = combined_data_export['DataType'].value_counts()\n",
        "print(f\"\\nData Type Distribution:\")\n",
        "for dtype, count in data_type_counts.items():\n",
        "    print(f\"  {dtype}: {count} records\")\n",
        "\n",
        "print(\"\\nPower BI Integration:\")\n",
        "print(\"The exported CSV contains 'Date', 'DataType', 'Model', and 'Value' columns.\")\n",
        "print(\"Use 'DataType' and 'Model' as slicers in Power BI for interactive analysis.\")\n",
        "print(\"Create time series visualizations filtered by data type and model.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a00199a0",
      "metadata": {
        "id": "a00199a0"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   Future forecasts were successfully generated for Linear Regression, Ridge Regression, Random Forest, Gradient Boosting, and Prophet models for the specified number of periods.\n",
        "*   The final DataFrame, containing the 'Date', 'DataType', 'Model', and 'Value' columns, was exported to a CSV file named `combined_oil_price_data_{time}.csv`.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The structured CSV file with 'DataType' and 'Model' columns is ideal for creating interactive dashboards in Power BI, allowing users to easily compare actuals, backtests, and forecasts across different models using slicers.\n",
        "*   The exported CSV file can be directly imported into Power BI for visualization and further analysis, facilitating the creation of time-series plots filtered by data type and model.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31a32934",
      "metadata": {
        "id": "31a32934"
      },
      "outputs": [],
      "source": [
        "# Cell 14: Validation Check\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"DATA VALIDATION\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "# Check for missing values\n",
        "missing_values = combined_data_export.isnull().sum()\n",
        "print(f\"Missing Values Check:\")\n",
        "for col, missing in missing_values.items():\n",
        "    if missing > 0:\n",
        "        print(f\"  {col}: {missing} missing values\")\n",
        "    else:\n",
        "        print(f\"  {col}: No missing values\")\n",
        "\n",
        "# Check date ranges\n",
        "print(f\"\\nDate Range Validation:\")\n",
        "print(f\"  Earliest Date: {combined_data_export[date_col].min()}\")\n",
        "print(f\"  Latest Date: {combined_data_export[date_col].max()}\")\n",
        "print(f\"  Total Date Range: {(combined_data_export[date_col].max() - combined_data_export[date_col].min()).days} days\")\n",
        "\n",
        "# Check value ranges\n",
        "print(f\"\\nValue Range Validation:\")\n",
        "print(f\"  Minimum Value: ${combined_data_export['Value'].min():.2f}\")\n",
        "print(f\"  Maximum Value: ${combined_data_export['Value'].max():.2f}\")\n",
        "print(f\"  Mean Value: ${combined_data_export['Value'].mean():.2f}\")\n",
        "\n",
        "print(\"\\nValidation complete - data is ready for Power BI import!\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
